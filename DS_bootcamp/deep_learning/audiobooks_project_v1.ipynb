{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4459e6",
   "metadata": {},
   "source": [
    "### Audiobooks project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb6eed9",
   "metadata": {},
   "source": [
    "### In this version the data is shuffled before balancing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d616b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a803c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9400e+02, 1.6200e+03, 1.6200e+03, ..., 5.0000e+00, 9.2000e+01,\n",
       "        0.0000e+00],\n",
       "       [1.1430e+03, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [2.0590e+03, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 3.8800e+02,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [3.1134e+04, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [3.2832e+04, 1.6200e+03, 1.6200e+03, ..., 0.0000e+00, 9.0000e+01,\n",
       "        0.0000e+00],\n",
       "       [2.5100e+02, 1.6740e+03, 3.3480e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "raw_csv_data = np.loadtxt('data/Audiobooks_data.csv', delimiter = \",\")\n",
    "raw_csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d76254d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00994</th>\n",
       "      <th>1620</th>\n",
       "      <th>1620.1</th>\n",
       "      <th>19.73</th>\n",
       "      <th>19.73.1</th>\n",
       "      <th>1</th>\n",
       "      <th>10.00</th>\n",
       "      <th>0.99</th>\n",
       "      <th>1603.80</th>\n",
       "      <th>5</th>\n",
       "      <th>92</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14083.000000</td>\n",
       "      <td>14083.000000</td>\n",
       "      <td>14083.000000</td>\n",
       "      <td>14083.000000</td>\n",
       "      <td>14083.000000</td>\n",
       "      <td>14083.000000</td>\n",
       "      <td>14083.000000</td>\n",
       "      <td>14083.000000</td>\n",
       "      <td>14083.000000</td>\n",
       "      <td>14083.000000</td>\n",
       "      <td>14083.000000</td>\n",
       "      <td>14083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16773.611943</td>\n",
       "      <td>1591.279646</td>\n",
       "      <td>1678.612796</td>\n",
       "      <td>7.102894</td>\n",
       "      <td>7.542940</td>\n",
       "      <td>0.160690</td>\n",
       "      <td>8.909717</td>\n",
       "      <td>0.125598</td>\n",
       "      <td>189.788585</td>\n",
       "      <td>0.069871</td>\n",
       "      <td>61.932898</td>\n",
       "      <td>0.158844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9691.239210</td>\n",
       "      <td>504.358512</td>\n",
       "      <td>654.861664</td>\n",
       "      <td>4.930700</td>\n",
       "      <td>5.559378</td>\n",
       "      <td>0.367258</td>\n",
       "      <td>0.643363</td>\n",
       "      <td>0.241104</td>\n",
       "      <td>370.905846</td>\n",
       "      <td>0.470342</td>\n",
       "      <td>88.210402</td>\n",
       "      <td>0.365544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8371.500000</td>\n",
       "      <td>1188.000000</td>\n",
       "      <td>1188.000000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16715.000000</td>\n",
       "      <td>1620.000000</td>\n",
       "      <td>1620.000000</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>6.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25187.500000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.910000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33683.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>130.940000</td>\n",
       "      <td>130.940000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              00994          1620        1620.1         19.73       19.73.1  \\\n",
       "count  14083.000000  14083.000000  14083.000000  14083.000000  14083.000000   \n",
       "mean   16773.611943   1591.279646   1678.612796      7.102894      7.542940   \n",
       "std     9691.239210    504.358512    654.861664      4.930700      5.559378   \n",
       "min        2.000000    216.000000    216.000000      3.860000      3.860000   \n",
       "25%     8371.500000   1188.000000   1188.000000      5.330000      5.330000   \n",
       "50%    16715.000000   1620.000000   1620.000000      5.950000      6.070000   \n",
       "75%    25187.500000   2160.000000   2160.000000      8.000000      8.000000   \n",
       "max    33683.000000   2160.000000   7020.000000    130.940000    130.940000   \n",
       "\n",
       "                  1         10.00          0.99       1603.80             5  \\\n",
       "count  14083.000000  14083.000000  14083.000000  14083.000000  14083.000000   \n",
       "mean       0.160690      8.909717      0.125598    189.788585      0.069871   \n",
       "std        0.367258      0.643363      0.241104    370.905846      0.470342   \n",
       "min        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      8.910000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      8.910000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      8.910000      0.130000    194.400000      0.000000   \n",
       "max        1.000000     10.000000      1.000000   2160.000000     30.000000   \n",
       "\n",
       "                 92             0  \n",
       "count  14083.000000  14083.000000  \n",
       "mean      61.932898      0.158844  \n",
       "std       88.210402      0.365544  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%       11.000000      0.000000  \n",
       "75%      105.000000      0.000000  \n",
       "max      464.000000      1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_d = pd.read_csv('data/Audiobooks_data.csv')\n",
    "raw_d.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7f2c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the firs column there is ID (we don't use it) and the last column are targets\n",
    "# We have to split this data:\n",
    "unscaled_inputs_all = raw_csv_data[:,1:-1] #all the rows, columns from 1 to -1 (excluded)\n",
    "targets_all = raw_csv_data[:,-1] #all the rows, only last column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028aba96",
   "metadata": {},
   "source": [
    "### Shuffling indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c7a6a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(unscaled_inputs_all.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "unscaled_inputs_all = unscaled_inputs_all[shuffled_indices]\n",
    "targets_all = targets_all[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e32492",
   "metadata": {},
   "source": [
    "#### The data is shuffled randomly so every time we reuse this notebook the data will be shuffled in different way. There is no random seed in here because this is the very basic and simple approach for EDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edbce36",
   "metadata": {},
   "source": [
    "### Balancing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2389b143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2237"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting 1's in the targets\n",
    "num_one_targets  = int(np.sum(targets_all))\n",
    "num_one_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ee5b9e",
   "metadata": {},
   "source": [
    "#### In this course the approach for balancing the dataset is to leave only the same amount of targets with 0 value as we have num_one_targets. The rest is going to be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23e2b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_targets_counter = 0\n",
    "indices_to_remove = []\n",
    "\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] == 0:\n",
    "        zero_targets_counter +=1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aec2ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis=0)\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c03eb",
   "metadata": {},
   "source": [
    "### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e002fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling using sklearn library (standardizing data along any axis)\n",
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0931f",
   "metadata": {},
   "source": [
    "### Shuffling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34975627",
   "metadata": {},
   "source": [
    "### Even though we shuffled the data at the beginning we still have to shuffle it after balancing the dataset. This is because otherwise we would have all \"1\" targets in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cd13c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e50d615",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5906e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the sizes of train, test and validations sets\n",
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "train_samples_count = int(0.8*samples_count)\n",
    "validation_samples_count = int(0.1*samples_count)\n",
    "test_samples_count = samples_count-train_samples_count-validation_samples_count\n",
    "\n",
    "# Splitting the data (manually)\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c9c7de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1796.0 3579 0.5018161497625035\n",
      "223.0 447 0.49888143176733774\n",
      "218.0 448 0.4866071428571428\n"
     ]
    }
   ],
   "source": [
    "# We can check if the splitted data is balanced as we intended:\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets/train_samples_count))\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets/validation_samples_count))\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets/test_samples_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718d66de",
   "metadata": {},
   "source": [
    "#### The second columns is the number of samples which for the first row (training set) should be much bigger than for the last two (val and test). In the last column all values should be around 0.5 (50%) which shows us the split. In this case everything is like it should be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf2abdd",
   "metadata": {},
   "source": [
    "### Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84611584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save the data in the zipped numpy file format (.npz) for future use\n",
    "np.savez('data/audiobooks_data_train_v1', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('data/audiobooks_data_validation_v1', inputs=validation_inputs, targets = validation_targets)\n",
    "np.savez('data/audiobooks_data_test_v1', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ca433",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
